{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RLKvfsyQbBLA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Packages"
      ],
      "metadata": {
        "id": "azMfY1sZbCo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import os\n",
        "from groq import Groq\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "G6p4_104bEAb"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# URL of the main page to scrape\n",
        "main_url = 'https://www.whitehouse.gov/briefing-room/'\n",
        "\n",
        "# Headers to mimic a real browser request\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36'\n",
        "}\n",
        "\n",
        "# Function to fetch the most recent article link\n",
        "def fetch_most_recent_article(url):\n",
        "    try:\n",
        "        # Request the main page\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        response.raise_for_status()  # Check for request errors\n",
        "\n",
        "        # Parse the HTML\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Locate the div with the articles and get the first article\n",
        "        article_wrapper = soup.find('div', class_='article-wrapper')\n",
        "\n",
        "        if article_wrapper:\n",
        "            # Get the most recent article (first one in the list)\n",
        "            recent_article = article_wrapper.find('article', class_='news-item')\n",
        "            if recent_article:\n",
        "                # Extract title, link, and date\n",
        "                title_tag = recent_article.find('a', class_='news-item__title')\n",
        "                title = title_tag.get_text(strip=True) if title_tag else \"No title\"\n",
        "                link = title_tag['href'] if title_tag else None\n",
        "                date_tag = recent_article.find('time', class_='posted-on')\n",
        "                date = date_tag.get_text(strip=True) if date_tag else \"No date\"\n",
        "\n",
        "                # Return the article details\n",
        "                return {\n",
        "                    'title': title,\n",
        "                    'link': link,\n",
        "                    'date': date\n",
        "                }\n",
        "        return None\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Failed to fetch main page: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to fetch and scrape the content of the article page\n",
        "def fetch_article_content(article_url):\n",
        "    try:\n",
        "        # Request the article page\n",
        "        response = requests.get(article_url, headers=headers, timeout=10)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Parse the article page\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Extract content; this might need adjustment based on the actual structure\n",
        "        content_div = soup.find('div', class_='article-body')\n",
        "        content = content_div.get_text(separator='\\n').strip() if content_div else \"Content not found.\"\n",
        "\n",
        "        return content\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Failed to fetch article page: {e}\")\n",
        "        return \"Error retrieving content.\"\n",
        "\n",
        "recent_article = fetch_most_recent_article(main_url)\n",
        "print(recent_article)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhgT8XTGeZZF",
        "outputId": "1ada8b77-319e-4fc1-c910-c7738d8b6e94"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching the most recent article...\n",
            "{'title': 'Remarks as Prepared for Delivery by First Lady JillBiden at a Reception Celebrating Culinary Arts inDiplomacy', 'link': 'https://www.whitehouse.gov/briefing-room/speeches-remarks/2024/11/12/remarks-as-prepared-for-delivery-by-first-lady-jill-biden-at-a-reception-celebrating-culinary-arts-in-diplomacy/', 'date': 'November 12, 2024'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# URL of the specific article page\n",
        "article_url = recent_article['link']\n",
        "\n",
        "# Headers to mimic a real browser request\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36'\n",
        "}\n",
        "\n",
        "# Function to fetch and parse the article content\n",
        "def fetch_article_body_content(url):\n",
        "    try:\n",
        "        # Request the article page\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        response.raise_for_status()  # Check for request errors\n",
        "\n",
        "        # Parse the article page HTML\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Locate the <article> tag with the specific class\n",
        "        article = soup.find('article', class_='post-108981 post type-post status-publish hentry category-speeches-remarks')\n",
        "\n",
        "        # Find the <section class=\"body-content\"> within the <article> tag\n",
        "        body_content_section = article.find('section', class_='body-content') if article else None\n",
        "\n",
        "        if body_content_section:\n",
        "            # Extract and combine all text within the <section> into a single string\n",
        "            content = ' '.join([p.get_text(strip=True) for p in body_content_section.find_all('p')])\n",
        "            return content\n",
        "        else:\n",
        "            return \"Content not found in the specified section.\"\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Failed to fetch article page: {e}\")\n",
        "        return \"Error retrieving content.\"\n",
        "\n",
        "# Fetch the content of the article body and print\n",
        "article_content = fetch_article_body_content(article_url)\n",
        "print(article_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liMIKjlWhwYC",
        "outputId": "8ba93b10-77a2-45f9-b1c2-c73207c0ecca"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oval Office 2:45 P.M. EST PRESIDENT BIDEN:  Well, Mr. President, welcome to the White House. PRESIDENT SUBIANTO:  Thank you very much, sir. PRESIDENT BIDEN:  Good to have you here.  And we’re making — PRESIDENT SUBIANTO:  Thank you very much. PRESIDENT BIDEN:  We’re marking an important anniversary: 75 years of diplomatic relationship with Indonesia and the United States — 75 years.  I’m proud that the partnership between our countries is stronger than it’s ever been. And today, we’re going to discuss how we continue to strengthen that partnership, first, in my view, by advancing free and open Indo-Pacific with ASEAN at its center.  As two of the largest democracies in the world, it seems to me that our nations have a special responsibility in this vision. Second, fighting the climate crisis.  Indonesia is a critical player in the clean energy transition. And third, by building a secure and resilient supply chain. And finally, by deepening our comprehensive strategic partnership that includes deepening our security cooperation. We’ll discuss, also, global challenges, including in Gaza and the South China Sea. So, Mr. President, I’m looking forward to our discussion, and welcome.  I’m delighted to have you here, and the floor is yours. PRESIDENT SUBIANTO:  Thank you.  Thank you, President Biden.  Thank you for receiving me. I also would like to thank you: You — you phoned me yourself upon my election and — PRESIDENT BIDEN:  A great victory. PRESIDENT SUBIANTO:  Yes.  Thank you very much. And then, finally, I could make it and you received me today. United States, for us, is a very great friend.  United States supported us in our struggle for independence and helped us many times in our time of need. Therefore, I will work very hard to strengthen Indonesia and United States’ relationship.  And I would like to work towards this end, that we have a strong cooperation. Once again, President Biden, thank you very much for receiving me. PRESIDENT BIDEN:  Well, thank you.  I look forward to our discussion. PRESIDENT SUBIANTO:  Thank you, sir. PRESIDENT BIDEN:  Thank you. PRESIDENT SUBIANTO:  Thank you, sir. 2:48 P.M. EST\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the client with the API key\n",
        "api_key = userdata.get('Groq')\n",
        "client = Groq(api_key=api_key)\n",
        "\n",
        "# Define the chat completion request using client.chat.completions.create()\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=\"llama3-8b-8192\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a non-partisan and non-biased bot attempting to give information to the general population. You are to limit your response to 560 characters.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": article_content\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Print the response content\n",
        "response = chat_completion.choices[0].message.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlGJI5MUmZJe",
        "outputId": "61bf3ffc-4728-4c69-974c-c897c5c90969"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement groq-client (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for groq-client\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "title = recent_article['title']\n",
        "link = recent_article['link']\n",
        "\n",
        "pp.pprint(recent_article['title'])\n",
        "pp.pprint(recent_article['link'])\n",
        "pp.pprint(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Aaqm0vcn298",
        "outputId": "c251b02c-c172-41e8-d5d8-7348bb117bbb"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Remarks as Prepared for Delivery by First Lady JillBiden at a Reception '\n",
            " 'Celebrating Culinary Arts inDiplomacy')\n",
            "'https://www.whitehouse.gov/briefing-room/speeches-remarks/2024/11/12/remarks-as-prepared-for-delivery-by-first-lady-jill-biden-at-a-reception-celebrating-culinary-arts-in-diplomacy/'\n",
            "('The President of Indonesia, Joko Widodo (Subianto), visited the White House '\n",
            " 'for a meeting with President Biden. They discussed strengthening their '\n",
            " \"countries' diplomatic relationship, which marks its 75th anniversary. Topics \"\n",
            " 'included advancing the Indo-Pacific region, fighting climate change, '\n",
            " 'building secure supply chains, and addressing global challenges.')\n"
          ]
        }
      ]
    }
  ]
}